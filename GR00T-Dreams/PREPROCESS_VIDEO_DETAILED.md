# preprocess_video.py - Chi Ti·∫øt Ph√¢n T√≠ch

## üìã M·ª•c ƒê√≠ch Ch√≠nh
Script n√†y **chia nh·ªè video (frames) th√†nh nhi·ªÅu camera views** v√† **chu·∫©n h√≥a k√≠ch th∆∞·ªõc** (256x256) v·ªõi padding ƒë·ªÉ gi·ªØ aspect ratio.

---

## üé¨ Input/Output

### **Input:**
```
IDM_dump/data/m2/
‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îî‚îÄ‚îÄ 1.txt
‚îî‚îÄ‚îÄ videos/
    ‚îî‚îÄ‚îÄ observation.images.cam_head/
        ‚îî‚îÄ‚îÄ 1.mp4  (832x480, ch·ª©a 3 camera views gh√©p v√†o 1 frame)
```

**Frame g·ªëc (832x480):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Camera 1  ‚îÇ  Camera 2       ‚îÇ  ‚Üê Chi·ªÅu cao: 240px
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Camera 3  ‚îÇ  (ph·∫ßn r·ªóng)    ‚îÇ  ‚Üê Chi·ªÅu cao: 240px
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 M·ªói camera: 416px chi·ªÅu r·ªông
```

### **Output:**
```
IDM_dump/data/m2_split/
‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îî‚îÄ‚îÄ 1.txt  (copy t·ª´ input)
‚îî‚îÄ‚îÄ videos/
    ‚îî‚îÄ‚îÄ observation.images.cam_head/
        ‚îî‚îÄ‚îÄ 1.mp4  (256x256, ƒë√£ normalize)
```

---

## üîç Chi Ti·∫øt C√°c H√†m

### **1. `extract_subimages(frame, ratio)`**

**M·ª•c ƒë√≠ch:** Chia frame 832x480 th√†nh 3 camera views, m·ªói view 240x416

```python
def extract_subimages(frame, ratio):
    h, w = frame.shape[:2]  # h=480, w=832
    
    half_width = w // 2   # 416
    half_height = h // 2  # 240
    
    # Extract 3 subimages
    image_side_0 = frame[:half_height, :half_width]      # [0:240, 0:416]   (top-left)
    image_side_1 = frame[:half_height, half_width:]      # [0:240, 416:832] (top-right)
    wrist_image = frame[half_height:, :half_width]       # [240:480, 0:416] (bottom-left)
```

**Visualization:**
```
Frame 832x480:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  [0:240,    ‚îÇ  [0:240,    ‚îÇ
‚îÇ   0:416]    ‚îÇ   416:832]  ‚îÇ  ‚Üê image_side_0, image_side_1
‚îÇ             ‚îÇ             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  [240:480,  ‚îÇ  (ignored)  ‚îÇ
‚îÇ   0:416]    ‚îÇ             ‚îÇ  ‚Üê wrist_image
‚îÇ             ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ti·∫øp theo:** Resize m·ªói view v·ªõi padding ƒë·ªÉ gi·ªØ aspect ratio:

```python
image_side_0 = resize_with_padding(image_side_0, ratio)  # 240x416 ‚Üí 256x256 (with padding)
image_side_1 = resize_with_padding(image_side_1, ratio)  # 240x416 ‚Üí 256x256 (with padding)
wrist_image = resize_with_padding(wrist_image, ratio)    # 240x416 ‚Üí 256x256 (with padding)

return image_side_0, image_side_1, wrist_image
```

---

### **2. `resize_with_padding(img, ratio=1.0, target_size=(256, 256))`**

**M·ª•c ƒë√≠ch:** Resize h√¨nh ·∫£nh v·ªõi padding ƒë·ªÉ gi·ªØ aspect ratio

```python
def resize_with_padding(img, ratio=1.0, target_size=(256, 256)):
    h, w = img.shape[:2]  # h=240, w=416
    target_ratio = ratio  # Aspect ratio c·∫ßn duy tr√¨
    
    if target_ratio >= 1:  # Width-based limiting
        # Resize theo width
        new_w = target_size[0]  # 256
        new_h = int(new_w / target_ratio)  # T√≠nh height d·ª±a tr√™n aspect ratio
        
        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # Th√™m padding tr√™n/d∆∞·ªõi ƒë·ªÉ fill 256x256
        pad_top = (target_size[1] - new_h) // 2
        pad_bottom = target_size[1] - new_h - pad_top
        padded = cv2.copyMakeBorder(resized, pad_top, pad_bottom, 0, 0, 
                                    cv2.BORDER_CONSTANT, value=[0, 0, 0])
    else:  # Height-based limiting
        # Resize theo height
        new_h = target_size[1]  # 256
        new_w = int(new_h * target_ratio)
        
        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # Th√™m padding tr√°i/ph·∫£i ƒë·ªÉ fill 256x256
        pad_left = (target_size[0] - new_w) // 2
        pad_right = target_size[0] - new_w - pad_left
        padded = cv2.copyMakeBorder(resized, 0, 0, pad_left, pad_right, 
                                    cv2.BORDER_CONSTANT, value=[0, 0, 0])
    
    return padded
```

**V√≠ d·ª•:**
```
Input: 240x416 (aspect ratio = 416/240 ‚âà 1.73)
Target: 256x256

V√¨ 1.73 > 1 ‚Üí Width-limited:
  new_w = 256
  new_h = int(256 / 1.73) ‚âà 148
  
  Resize ‚Üí 256x148
  
  Th√™m padding:
  pad_top = (256 - 148) / 2 = 54
  pad_bottom = 256 - 148 - 54 = 54
  
  Result: 256x256 v·ªõi h√¨nh ·∫£nh ·ªü gi·ªØa, 54px ƒëen tr√™n/d∆∞·ªõi
```

---

### **3. `extract_subimages_franka(frame, original_width, original_height)`**

**M·ª•c ƒë√≠ch:** T∆∞∆°ng t·ª± `extract_subimages()` nh∆∞ng resize theo original_width/height thay v√¨ padding

```python
def extract_subimages_franka(frame, original_width, original_height):
    h, w = frame.shape[:2]  # 480, 832
    
    half_width = w // 2   # 416
    half_height = h // 2  # 240
    
    # Extract
    image_side_0 = frame[:half_height, :half_width]      # 240x416
    image_side_1 = frame[:half_height, half_width:]      # 240x416
    wrist_image = frame[half_height:, :half_width]       # 240x416
    
    # Resize KH√îNG d√πng padding, ch·ªâ scale tr·ª±c ti·∫øp
    image_side_0 = cv2.resize(image_side_0, (original_width, original_height), 
                              interpolation=cv2.INTER_LINEAR)  # 1280x800
    image_side_1 = cv2.resize(image_side_1, (original_width, original_height), ...)
    wrist_image = cv2.resize(wrist_image, (original_width, original_height), ...)
    
    return image_side_0, image_side_1, wrist_image
```

**Kh√°c bi·ªát so v·ªõi `resize_with_padding()`:**
- `resize_with_padding()`: Gi·ªØ aspect ratio + th√™m padding (ƒëen) ƒë·ªÉ fill 256x256
- `extract_subimages_franka()`: Resize tr·ª±c ti·∫øp kh√¥ng gi·ªØ aspect ratio (b√≥p m√©o h√¨nh)

---

### **4. `custom_crop_pad_resize_gr1(img, target_size=(256, 256))`**

**M·ª•c ƒë√≠ch:** X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho dataset GR1 - crop + pad + resize

```python
def custom_crop_pad_resize_gr1(img, target_size=(256, 256)):
    original_height, original_width = img.shape[:2]
    
    # Step 1: CROP d·ª±a tr√™n t·ª∑ l·ªá
    # Original crop cho 1280x800: (310, 770, 110, 1130) - (top, bottom, left, right)
    crop_top_ratio = 310 / 800      # T·ª∑ l·ªá top
    crop_bottom_ratio = 770 / 800   # T·ª∑ l·ªá bottom
    crop_left_ratio = 110 / 1280    # T·ª∑ l·ªá left
    crop_right_ratio = 1130 / 1280  # T·ª∑ l·ªá right
    
    # Apply ratios
    crop_top = int(original_height * crop_top_ratio)
    crop_bottom = int(original_height * crop_bottom_ratio)
    crop_left = int(original_width * crop_left_ratio)
    crop_right = int(original_width * crop_right_ratio)
    
    # Crop
    img_cropped = img[crop_top:crop_bottom, crop_left:crop_right]
    
    # Step 2: RESIZE ƒë·∫øn intermediate size
    intermediate_height = 480
    intermediate_width = 720
    img_resized = cv2.resize(img_cropped, (intermediate_width, intermediate_height), cv2.INTER_AREA)
    
    # Step 3: PAD ƒë·ªÉ th√†nh square
    if intermediate_width > intermediate_height:  # 720 > 480 ‚Üí width larger
        height_pad = (intermediate_width - intermediate_height) // 2  # (720-480)/2 = 120
        img_pad = np.pad(img_resized, ((height_pad, height_pad), (0, 0), (0, 0)), 
                        mode="constant", constant_values=0)  # Pad top/bottom 120px
    
    # Step 4: RESIZE ƒë·∫øn target size (256x256)
    final_img = cv2.resize(img_pad, target_size, cv2.INTER_AREA)
    
    return final_img
```

**Flow:**
```
Input frame (832x480)
    ‚Üì (CROP theo t·ª∑ l·ªá)
Cropped image
    ‚Üì (RESIZE ‚Üí 720x480)
Intermediate 720x480
    ‚Üì (PAD ‚Üí 720x720)
Padded square 720x720
    ‚Üì (RESIZE ‚Üí 256x256)
Final output 256x256
```

---

### **5. `process_batch_frames(frames, output_videos, ...)`**

**M·ª•c ƒë√≠ch:** X·ª≠ l√Ω batch frame v√† ghi v√†o output video writers

```python
def process_batch_frames(frames, output_videos, src_path, dataset, 
                         original_width, original_height):
    ratio = original_width / original_height  # Aspect ratio
    
    for frame in frames:
        if dataset == 'robocasa':
            # Chia th√†nh 3 views v·ªõi padding
            image_side_0, image_side_1, wrist_image = extract_subimages(frame, ratio)
            output_videos['observation.images.left_view'].append_data(image_side_0)
            output_videos['observation.images.right_view'].append_data(image_side_1)
            output_videos['observation.images.wrist_view'].append_data(wrist_image)
            
        elif dataset == 'gr1':
            # Custom crop+pad+resize
            image = custom_crop_pad_resize_gr1(frame)
            output_videos['observation.images.ego_view'].append_data(image)
            
        elif dataset == 'franka':
            # Chia th√†nh 3 views S·ª∞ D·ª§NG franka extraction
            image_side_0, image_side_1, wrist_image = extract_subimages_franka(
                frame, original_width, original_height
            )
            output_videos['observation.images.exterior_image_1_left_pad_res256_freq15'].append_data(image_side_0)
            output_videos['observation.images.exterior_image_2_left_pad_res256_freq15'].append_data(image_side_1)
            output_videos['observation.images.wrist_image_left_pad_res256_freq15'].append_data(wrist_image)
```

---

### **6. `process_video(args)`**

**M·ª•c ƒë√≠ch:** X·ª≠ l√Ω 1 video t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi

```python
def process_video(args):
    src_path, dst_dir, video_name, dataset, original_width, original_height = args
    
    # Step 1: T·∫°o output directories d·ª±a tr√™n dataset type
    if dataset == 'robocasa':
        output_dirs = {
            'observation.images.left_view': ...,
            'observation.images.right_view': ...,
            'observation.images.wrist_view': ...,
        }
    elif dataset == 'gr1':
        output_dirs = {
            'observation.images.ego_view': ...,
        }
    # ... (kh√°c dataset kh√°c dirs)
    
    # Step 2: M·ªü video v·ªõi decord
    vr = decord.VideoReader(src_path)
    fps = vr.get_avg_fps()
    frame_count = len(vr)
    
    # Step 3: T·∫°o video writers cho m·ªói output
    output_videos = {}
    for name, dir_path in output_dirs.items():
        output_videos[name] = imageio.get_writer(os.path.join(dir_path, f"{video_name}.mp4"), fps=fps)
    
    # Step 4: ƒê·ªçc frames th√†nh batch
    batch_size = 32
    frames_batch = []
    pbar = tqdm(total=frame_count, desc=f"Processing {video_name}", leave=False)
    
    for frame in vr:
        frames_batch.append(frame.asnumpy())
        
        if len(frames_batch) >= batch_size:
            # X·ª≠ l√Ω batch n√†y
            process_batch_frames(frames_batch, output_videos, src_path, dataset, 
                                original_width, original_height)
            frames_batch = []
            pbar.update(batch_size)
    
    # Step 5: X·ª≠ l√Ω frames c√≤n l·∫°i
    if frames_batch:
        process_batch_frames(frames_batch, output_videos, src_path, dataset, 
                            original_width, original_height)
        pbar.update(len(frames_batch))
    
    pbar.close()
    
    # Step 6: Close writers
    for writer in output_videos.values():
        writer.close()
```

**Trong 1 video:**
1. M·ªü video input (src_path)
2. T·∫°o output video files (1, 3 ho·∫∑c N t√πy dataset)
3. ƒê·ªçc frames th√†nh batch (batch_size=32)
4. X·ª≠ l√Ω batch (crop/resize)
5. Ghi v√†o output videos
6. ƒê√≥ng t·∫•t c·∫£ files

---

### **7. `copy_labels(src_dir, dst_dir)`**

**M·ª•c ƒë√≠ch:** Copy file .txt t·ª´ input labels ‚Üí output labels

```python
def copy_labels(src_dir, dst_dir):
    src_labels_dir = os.path.join(src_dir, 'labels')
    dst_labels_dir = os.path.join(dst_dir, 'labels')
    
    if os.path.exists(src_labels_dir):
        os.makedirs(dst_labels_dir, exist_ok=True)
        for label_file in os.listdir(src_labels_dir):
            if label_file.endswith('.txt'):
                shutil.copy2(
                    os.path.join(src_labels_dir, label_file),
                    os.path.join(dst_labels_dir, label_file)
                )
```

---

### **8. `process_subdirectory()` & `process_directory()`**

**M·ª•c ƒë√≠ch:** X·ª≠ l√Ω nhi·ªÅu videos trong parallel

```python
def process_subdirectory(subdir, src_dir, dst_dir, num_workers, ...):
    # Copy labels
    copy_labels(src_subdir, dst_subdir)
    
    # L·∫•y t·∫•t c·∫£ .mp4 files
    video_files = [f for f in os.listdir(src_videos_dir) if f.endswith('.mp4')]
    
    # T·∫°o args list cho m·ªói video
    args_list = [
        (mp4_path, dst_subdir, video_name, dataset, original_width, original_height)
        for video in video_files
    ]
    
    # Process v·ªõi multiprocessing
    with mp.Pool(num_workers) as pool:
        list(tqdm(pool.imap(process_video, args_list), total=len(args_list)))

def process_directory(src_dir, dst_dir, num_workers=None, ...):
    # X√°c ƒë·ªãnh subdirectories
    if recursive:
        subdirs = [d for d in os.listdir(src_dir) if os.path.isdir(...)]
    else:
        subdirs = ['']  # Ch·ªâ root
    
    # Process subdirs trong parallel (ThreadPoolExecutor)
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        list(executor.map(process_subdir_fn, subdirs))
```

**Parallelization:**
- **Level 1:** `ThreadPoolExecutor` ƒë·ªÉ process subdirectories (sequential by default)
- **Level 2:** `multiprocessing.Pool` ƒë·ªÉ process videos trong parallel

---

## üìä Data Flow

```
Input video (832x480, 93 frames, 1 MP4)
    ‚Üì
[Video Reader - decord]
    ‚Üì
ƒê·ªçc frames batch (batch_size=32)
    ‚Üì
[extract_subimages / custom_crop_pad_resize_gr1 / extract_subimages_franka]
    ‚Üì
3 processed frames (256x256) ho·∫∑c 1 processed frame (t√πy dataset)
    ‚Üì
[Video Writer - imageio]
    ‚Üì
Output: 1-3 MP4 files (256x256, 93 frames m·ªói file)

‚îå‚îÄ robocasa  ‚Üí 3 videos (left, right, wrist)
‚îú‚îÄ gr1       ‚Üí 1 video (ego_view)
‚îú‚îÄ franka    ‚Üí 3 videos (exterior1, exterior2, wrist)
‚îú‚îÄ so100     ‚Üí 1 video (webcam)
‚îî‚îÄ g1        ‚Üí 1 video (cam_head)
```

---

## ‚úÖ Summary

| H√†m | Input | Output | M·ª•c ƒë√≠ch |
|-----|-------|--------|---------|
| `extract_subimages()` | 832x480 frame | 3x 256x256 frames (with padding) | Chia 3 views + resize v·ªõi padding |
| `resize_with_padding()` | 240x416 frame | 256x256 frame | Resize gi·ªØ aspect ratio + padding |
| `custom_crop_pad_resize_gr1()` | 832x480 frame | 256x256 frame | Crop + pad + resize cho GR1 |
| `extract_subimages_franka()` | 832x480 frame | 3x 1280x800 frames | Chia 3 views + resize direct (b√≥p m√©o) |
| `process_batch_frames()` | Batch frames | Append data to writers | X·ª≠ l√Ω batch frames |
| `process_video()` | 1 MP4 file | 1-3 MP4 files (processed) | To√†n b·ªô flow 1 video |
| `copy_labels()` | Source labels dir | Destination labels dir | Copy .txt files |
| `process_directory()` | Source dir | Destination dir | Orchestrate to√†n b·ªô pipeline |

---

## üéØ Dataset Types

```
robocasa:  3 cameras ‚Üí left_view, right_view, wrist_view (256x256 each)
gr1:       1 camera  ‚Üí ego_view (256x256)
franka:    3 cameras ‚Üí exterior_image_1, exterior_image_2, wrist_image (custom size)
so100:     1 camera  ‚Üí webcam (256x256)
g1:        1 camera  ‚Üí cam_head (256x256)
```

