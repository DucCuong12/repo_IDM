{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fd87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def natural_sort(l):\n",
    "    return sorted(l, key=lambda x: [int(t) if t.isdigit() else t for t in re.findall(r'\\d+|\\D+', x)])\n",
    "\n",
    "def resize_with_padding(img, target_size=(256, 256)):\n",
    "    # Force RGB first\n",
    "    if img.ndim == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape[2] == 4:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # FIXED SCALE\n",
    "    scale = min(target_size[1] / w, target_size[0] / h)\n",
    "\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    pad_w = target_size[1] - new_w\n",
    "    pad_h = target_size[0] - new_h\n",
    "\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        pad_top,\n",
    "        pad_bottom,\n",
    "        pad_left,\n",
    "        pad_right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=(0, 0, 0),\n",
    "    )\n",
    "\n",
    "    # Hard assert\n",
    "    assert padded.shape == (target_size[0], target_size[1], 3), padded.shape\n",
    "\n",
    "    return padded.astype(np.uint8)\n",
    "def images_to_video(images_dir, output_video, fps=30, target_size=(256, 256)):\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(images_dir)\n",
    "        if f.lower().endswith((\".jpg\", \".png\"))\n",
    "    ])\n",
    "\n",
    "    Path(os.path.dirname(output_video)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = imageio.get_writer(\n",
    "        output_video,\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        format=\"FFMPEG\"   # üî• critical\n",
    "    )\n",
    "\n",
    "    for img_file in tqdm(image_files, desc=\"Frames to video\"):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "\n",
    "        frame = imageio.imread(img_path)\n",
    "        frame = resize_with_padding(frame, target_size)\n",
    "        frame = np.ascontiguousarray(frame, dtype=np.uint8)\n",
    "\n",
    "        if frame.shape != (target_size[0], target_size[1], 3):\n",
    "            print(\"‚ùå Skip:\", img_file, frame.shape)\n",
    "            continue\n",
    "\n",
    "        writer.append_data(frame)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"‚úÖ Video saved:\", output_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa327b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames to video: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1611/1611 [00:07<00:00, 202.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video saved: /media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000_lerobot.data/videos/chunk-000/observation.images.cam_head/episode_000000.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng:\n",
    "images_dir = \"/media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000/images\"\n",
    "output_video = \"/media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000_lerobot.data/videos/chunk-000/observation.images.cam_head/episode_000000.mp4\"\n",
    "Path(os.path.dirname(output_video)).mkdir(parents=True, exist_ok=True)\n",
    "images_to_video(images_dir, output_video, fps=30, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n g·ªëc\n",
    "src_folder = \"episode_0000\"\n",
    "dst_folder = \"episode_0000_lerobot.data\"\n",
    "\n",
    "# T·∫°o c√°c th∆∞ m·ª•c ƒë√≠ch\n",
    "os.makedirs(f\"{dst_folder}/data/chunk-000\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/videos/chunk-000/observation.images.cam_head\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/meta\", exist_ok=True)\n",
    "\n",
    "# Copy ·∫£nh sang ƒë√∫ng v·ªã tr√≠\n",
    "src_images = Path(f\"{src_folder}/images\")\n",
    "dst_images = Path(f\"{dst_folder}/videos/chunk-000/observation.images.cam_head\")\n",
    "images_to_video(images_dir, output_video, fps=30, target_size=(256, 256))\n",
    "\n",
    "# ƒê·ªçc metadata\n",
    "with open(f\"{src_folder}/metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# ƒê·ªçc trajectory: CHU·∫®N cho file d·∫°ng {'frames': [...]}\n",
    "trajectory = []\n",
    "with open(f\"{src_folder}/trajectory.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    if isinstance(data, dict) and \"frames\" in data:\n",
    "        print(\"T·ªïng s·ªë frame trong file:\", len(data[\"frames\"]))\n",
    "        trajectory = []\n",
    "        for i, frame in enumerate(data[\"frames\"]):\n",
    "            if isinstance(frame, dict):\n",
    "                if \"states\" in frame and \"actions\" in frame:\n",
    "                    trajectory.append(frame)\n",
    "                else:\n",
    "                    print(f\"Frame {i} thi·∫øu 'states' ho·∫∑c 'actions'\")\n",
    "            else:\n",
    "                print(f\"Frame {i} kh√¥ng ph·∫£i dict:\", type(frame))\n",
    "    else:\n",
    "        raise RuntimeError(\"File trajectory.json kh√¥ng ƒë√∫ng format dict['frames'].\")\n",
    "\n",
    "print(\"S·ªë frame h·ª£p l·ªá:\", len(trajectory))\n",
    "if not trajectory:\n",
    "    raise RuntimeError(\"Kh√¥ng t√¨m th·∫•y frame h·ª£p l·ªá trong trajectory.json!\")\n",
    "\n",
    "\n",
    "\n",
    "if not trajectory:\n",
    "    raise RuntimeError(\"Kh√¥ng t√¨m th·∫•y frame h·ª£p l·ªá trong trajectory.json!\")\n",
    "\n",
    "# T·∫°o DataFrame cho LeRobot\n",
    "states = [traj['states'] for traj in trajectory]\n",
    "actions = [traj['actions'] for traj in trajectory]\n",
    "# N·∫øu states/actions l√† dict nhi·ªÅu key, b·∫°n c·∫ßn flatten ho·∫∑c ch·ªçn key ph√π h·ª£p\n",
    "# V√≠ d·ª•: flatten t·∫•t c·∫£ value th√†nh 1 list\n",
    "def flatten_state_action(item):\n",
    "    out = []\n",
    "    for v in item.values():\n",
    "        if isinstance(v, dict):\n",
    "            out.extend(flatten_state_action(v))\n",
    "        elif isinstance(v, list):\n",
    "            out.extend(v)\n",
    "        else:\n",
    "            out.append(v)\n",
    "    return out\n",
    "\n",
    "states_flat = [flatten_state_action(s) for s in states]\n",
    "actions_flat = [flatten_state_action(a) for a in actions]\n",
    "\n",
    "num_frames = len(states_flat)\n",
    "fps = metadata.get(\"fps\", 30)\n",
    "timestamps = np.arange(num_frames) / fps\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'observation.state': states_flat,\n",
    "    'action': actions_flat,\n",
    "    'timestamp': timestamps.tolist(),\n",
    "    'episode_index': [0] * num_frames,\n",
    "    'index': list(range(num_frames)),\n",
    "    'task_index': [0] * num_frames,\n",
    "    'annotation.human.annotation.task': [metadata.get(\"task\", \"unknown\")] * num_frames,\n",
    "})\n",
    "\n",
    "parquet_path = f\"{dst_folder}/data/chunk-000/episode_000000.parquet\"\n",
    "df.to_parquet(parquet_path)\n",
    "\n",
    "# T·∫°o file meta/modality.json\n",
    "modality = {\n",
    "    \"video\": [\"observation.images.cam_head\"],\n",
    "    \"state\": list(metadata.get(\"state_keys\", [])),\n",
    "    \"action\": list(metadata.get(\"action_keys\", [])),\n",
    "    \"language\": list(metadata.get(\"language_keys\", []))\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/modality.json\", \"w\") as f:\n",
    "    json.dump(modality, f, indent=2)\n",
    "\n",
    "# T·∫°o file meta/info.json\n",
    "info = {\n",
    "    \"embodiment_tag\": \"m2\",\n",
    "    \"num_episodes\": 1,\n",
    "    \"other_info\": metadata.get(\"other_info\", {})\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/info.json\", \"w\") as f:\n",
    "    json.dump(info, f, indent=2)\n",
    "\n",
    "# T·∫°o file meta/episodes.jsonl\n",
    "with open(f\"{dst_folder}/meta/episodes.jsonl\", \"w\") as f:\n",
    "    f.write(json.dumps({\"episode_id\": \"0000\", \"length\": num_frames}) + \"\\n\")\n",
    "\n",
    "# T·∫°o file meta/tasks.jsonl (n·∫øu c√≥)\n",
    "if \"tasks\" in metadata:\n",
    "    with open(f\"{dst_folder}/meta/tasks.jsonl\", \"w\") as f:\n",
    "        for task in metadata[\"tasks\"]:\n",
    "            f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "# T·∫°o file meta/stats.json\n",
    "state_array = np.array(states_flat)\n",
    "action_array = np.array(actions_flat)\n",
    "stats = {\n",
    "    \"state\": {\n",
    "        \"mean\": state_array.mean(axis=0).tolist(),\n",
    "        \"std\": state_array.std(axis=0).tolist(),\n",
    "        \"min\": state_array.min(axis=0).tolist(),\n",
    "        \"max\": state_array.max(axis=0).tolist()\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"mean\": action_array.mean(axis=0).tolist(),\n",
    "        \"std\": action_array.std(axis=0).tolist(),\n",
    "        \"min\": action_array.min(axis=0).tolist(),\n",
    "        \"max\": action_array.max(axis=0).tolist()\n",
    "    }\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang format LeRobot!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuong310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
