{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fd87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def natural_sort(l):\n",
    "    return sorted(l, key=lambda x: [int(t) if t.isdigit() else t for t in re.findall(r'\\d+|\\D+', x)])\n",
    "\n",
    "def resize_with_padding(img, target_size=(256, 256)):\n",
    "    # Force RGB first\n",
    "    if img.ndim == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape[2] == 4:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # FIXED SCALE\n",
    "    scale = min(target_size[1] / w, target_size[0] / h)\n",
    "\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    pad_w = target_size[1] - new_w\n",
    "    pad_h = target_size[0] - new_h\n",
    "\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        pad_top,\n",
    "        pad_bottom,\n",
    "        pad_left,\n",
    "        pad_right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=(0, 0, 0),\n",
    "    )\n",
    "\n",
    "    # Hard assert\n",
    "    assert padded.shape == (target_size[0], target_size[1], 3), padded.shape\n",
    "\n",
    "    return padded.astype(np.uint8)\n",
    "def images_to_video(images_dir, output_video, fps=30, target_size=(256, 256)):\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(images_dir)\n",
    "        if f.lower().endswith((\".jpg\", \".png\"))\n",
    "    ])\n",
    "\n",
    "    Path(os.path.dirname(output_video)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = imageio.get_writer(\n",
    "        output_video,\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        format=\"FFMPEG\"   # üî• critical\n",
    "    )\n",
    "\n",
    "    for img_file in tqdm(image_files, desc=\"Frames to video\"):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "\n",
    "        frame = imageio.imread(img_path)\n",
    "        frame = resize_with_padding(frame, target_size)\n",
    "        frame = np.ascontiguousarray(frame, dtype=np.uint8)\n",
    "\n",
    "        if frame.shape != (target_size[0], target_size[1], 3):\n",
    "            print(\"‚ùå Skip:\", img_file, frame.shape)\n",
    "            continue\n",
    "\n",
    "        writer.append_data(frame)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"‚úÖ Video saved:\", output_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa327b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames to video: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1611/1611 [00:07<00:00, 202.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video saved: /media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000_lerobot.data/videos/chunk-000/observation.images.cam_head/episode_000000.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng:\n",
    "images_dir = \"/media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000/images\"\n",
    "output_video = \"/media/aitv/32202CEA64082D5F/cuong/repo_IDM/GR00T-Dreams/IDM_dump/data/episode_0000_lerobot.data/videos/chunk-000/observation.images.cam_head/episode_000000.mp4\"\n",
    "Path(os.path.dirname(output_video)).mkdir(parents=True, exist_ok=True)\n",
    "images_to_video(images_dir, output_video, fps=30, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n g·ªëc\n",
    "src_folder = \"episode_0000\"\n",
    "dst_folder = \"episode_0000_lerobot.data\"\n",
    "\n",
    "# T·∫°o c√°c th∆∞ m·ª•c ƒë√≠ch\n",
    "os.makedirs(f\"{dst_folder}/data/chunk-000\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/videos/chunk-000/observation.images.cam_head\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/meta\", exist_ok=True)\n",
    "\n",
    "# Copy ·∫£nh sang ƒë√∫ng v·ªã tr√≠\n",
    "src_images = Path(f\"{src_folder}/images\")\n",
    "dst_images = Path(f\"{dst_folder}/videos/chunk-000/observation.images.cam_head\")\n",
    "images_to_video(images_dir, output_video, fps=30, target_size=(256, 256))\n",
    "\n",
    "# ƒê·ªçc metadata\n",
    "with open(f\"{src_folder}/metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# ƒê·ªçc trajectory: CHU·∫®N cho file d·∫°ng {'frames': [...]}\n",
    "trajectory = []\n",
    "with open(f\"{src_folder}/trajectory.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    if isinstance(data, dict) and \"frames\" in data:\n",
    "        print(\"T·ªïng s·ªë frame trong file:\", len(data[\"frames\"]))\n",
    "        trajectory = []\n",
    "        for i, frame in enumerate(data[\"frames\"]):\n",
    "            if isinstance(frame, dict):\n",
    "                if \"states\" in frame and \"actions\" in frame:\n",
    "                    trajectory.append(frame)\n",
    "                else:\n",
    "                    print(f\"Frame {i} thi·∫øu 'states' ho·∫∑c 'actions'\")\n",
    "            else:\n",
    "                print(f\"Frame {i} kh√¥ng ph·∫£i dict:\", type(frame))\n",
    "    else:\n",
    "        raise RuntimeError(\"File trajectory.json kh√¥ng ƒë√∫ng format dict['frames'].\")\n",
    "\n",
    "print(\"S·ªë frame h·ª£p l·ªá:\", len(trajectory))\n",
    "if not trajectory:\n",
    "    raise RuntimeError(\"Kh√¥ng t√¨m th·∫•y frame h·ª£p l·ªá trong trajectory.json!\")\n",
    "\n",
    "\n",
    "\n",
    "if not trajectory:\n",
    "    raise RuntimeError(\"Kh√¥ng t√¨m th·∫•y frame h·ª£p l·ªá trong trajectory.json!\")\n",
    "\n",
    "# T·∫°o DataFrame cho LeRobot\n",
    "states = [traj['states'] for traj in trajectory]\n",
    "actions = [traj['actions'] for traj in trajectory]\n",
    "# N·∫øu states/actions l√† dict nhi·ªÅu key, b·∫°n c·∫ßn flatten ho·∫∑c ch·ªçn key ph√π h·ª£p\n",
    "# V√≠ d·ª•: flatten t·∫•t c·∫£ value th√†nh 1 list\n",
    "def flatten_state_action(item):\n",
    "    out = []\n",
    "    for v in item.values():\n",
    "        if isinstance(v, dict):\n",
    "            out.extend(flatten_state_action(v))\n",
    "        elif isinstance(v, list):\n",
    "            out.extend(v)\n",
    "        else:\n",
    "            out.append(v)\n",
    "    return out\n",
    "\n",
    "states_flat = [flatten_state_action(s) for s in states]\n",
    "actions_flat = [flatten_state_action(a) for a in actions]\n",
    "\n",
    "num_frames = len(states_flat)\n",
    "fps = metadata.get(\"fps\", 30)\n",
    "timestamps = np.arange(num_frames) / fps\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'observation.state': states_flat,\n",
    "    'action': actions_flat,\n",
    "    'timestamp': timestamps.tolist(),\n",
    "    'episode_index': [0] * num_frames,\n",
    "    'index': list(range(num_frames)),\n",
    "    'task_index': [0] * num_frames,\n",
    "    'annotation.human.annotation.task': [metadata.get(\"task\", \"unknown\")] * num_frames,\n",
    "})\n",
    "\n",
    "parquet_path = f\"{dst_folder}/data/chunk-000/episode_000000.parquet\"\n",
    "df.to_parquet(parquet_path)\n",
    "\n",
    "# T·∫°o file meta/modality.json\n",
    "modality = {\n",
    "    \"video\": [\"observation.images.cam_head\"],\n",
    "    \"state\": list(metadata.get(\"state_keys\", [])),\n",
    "    \"action\": list(metadata.get(\"action_keys\", [])),\n",
    "    \"language\": list(metadata.get(\"language_keys\", []))\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/modality.json\", \"w\") as f:\n",
    "    json.dump(modality, f, indent=2)\n",
    "\n",
    "# T·∫°o file meta/info.json\n",
    "info = {\n",
    "    \"embodiment_tag\": \"m2\",\n",
    "    \"num_episodes\": 1,\n",
    "    \"other_info\": metadata.get(\"other_info\", {})\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/info.json\", \"w\") as f:\n",
    "    json.dump(info, f, indent=2)\n",
    "\n",
    "# T·∫°o file meta/episodes.jsonl\n",
    "with open(f\"{dst_folder}/meta/episodes.jsonl\", \"w\") as f:\n",
    "    f.write(json.dumps({\"episode_id\": \"0000\", \"length\": num_frames}) + \"\\n\")\n",
    "\n",
    "# T·∫°o file meta/tasks.jsonl (n·∫øu c√≥)\n",
    "if \"tasks\" in metadata:\n",
    "    with open(f\"{dst_folder}/meta/tasks.jsonl\", \"w\") as f:\n",
    "        for task in metadata[\"tasks\"]:\n",
    "            f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "# T·∫°o file meta/stats.json\n",
    "state_array = np.array(states_flat)\n",
    "action_array = np.array(actions_flat)\n",
    "stats = {\n",
    "    \"state\": {\n",
    "        \"mean\": state_array.mean(axis=0).tolist(),\n",
    "        \"std\": state_array.std(axis=0).tolist(),\n",
    "        \"min\": state_array.min(axis=0).tolist(),\n",
    "        \"max\": state_array.max(axis=0).tolist()\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"mean\": action_array.mean(axis=0).tolist(),\n",
    "        \"std\": action_array.std(axis=0).tolist(),\n",
    "        \"min\": action_array.min(axis=0).tolist(),\n",
    "        \"max\": action_array.max(axis=0).tolist()\n",
    "    }\n",
    "}\n",
    "with open(f\"{dst_folder}/meta/stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang format LeRobot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8593c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_3023128/3137399483.py:37: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  frame = imageio.imread(img_path)\n",
      "Episodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:20<00:00, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted multi-episode dataset to LeRobot format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "############################\n",
    "# CONFIG\n",
    "############################\n",
    "\n",
    "src_root = os.getcwd()     # ch·ª©a episode_0000, episode_0001...\n",
    "dst_folder = \"resore.data\"\n",
    "\n",
    "episodes = sorted([\n",
    "    f for f in os.listdir(src_root)\n",
    "    if f.startswith(\"episode_\") and os.path.isdir(f) and len(f.split('_')[-1])==4\n",
    "])\n",
    "\n",
    "os.makedirs(f\"{dst_folder}/data/chunk-000\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/videos/chunk-000/observation.images.cam_head\", exist_ok=True)\n",
    "os.makedirs(f\"{dst_folder}/meta\", exist_ok=True)\n",
    "\n",
    "all_states = []\n",
    "all_actions = []\n",
    "episodes_jsonl = []\n",
    "\n",
    "metadata_ref = None\n",
    "\n",
    "for epi_idx, ep in enumerate(tqdm(episodes, desc=\"Episodes\")):\n",
    "\n",
    "    src_folder = ep\n",
    "\n",
    "    ################ VIDEO ################\n",
    "\n",
    "    images_dir = Path(f\"{src_folder}/images\")\n",
    "    video_path = f\"{dst_folder}/videos/chunk-000/observation.images.cam_head/episode_{epi_idx:06d}.mp4\"\n",
    "\n",
    "    images_to_video(images_dir, video_path)\n",
    "\n",
    "    ################ METADATA ################\n",
    "\n",
    "    with open(f\"{src_folder}/metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    if metadata_ref is None:\n",
    "        metadata_ref = metadata\n",
    "\n",
    "    ################ TRAJECTORY ################\n",
    "\n",
    "    with open(f\"{src_folder}/trajectory.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    trajectory = []\n",
    "    for frame in data[\"frames\"]:\n",
    "        if isinstance(frame,dict) and \"states\" in frame and \"actions\" in frame:\n",
    "            trajectory.append(frame)\n",
    "\n",
    "    if not trajectory:\n",
    "        raise RuntimeError(f\"{ep}: empty trajectory\")\n",
    "\n",
    "    states = [flatten_state_action(t[\"states\"]) for t in trajectory]\n",
    "    actions = [flatten_state_action(t[\"actions\"]) for t in trajectory]\n",
    "\n",
    "    all_states.extend(states)\n",
    "    all_actions.extend(actions)\n",
    "\n",
    "    num_frames = len(states)\n",
    "    fps = metadata.get(\"fps\",30)\n",
    "    timestamps = np.arange(num_frames)/fps\n",
    "\n",
    "    ################ PARQUET ################\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"observation.state\": states,\n",
    "        \"action\": actions,\n",
    "        \"timestamp\": timestamps.tolist(),\n",
    "        \"episode_index\": [epi_idx]*num_frames,\n",
    "        \"index\": list(range(num_frames)),\n",
    "        \"task_index\": [0]*num_frames,\n",
    "        \"annotation.human.annotation.task\": [metadata.get(\"task\",\"unknown\")]*num_frames,\n",
    "    })\n",
    "\n",
    "    pq = f\"{dst_folder}/data/chunk-000/episode_{epi_idx:06d}.parquet\"\n",
    "    df.to_parquet(pq)\n",
    "\n",
    "    episodes_jsonl.append({\n",
    "        \"episode_id\": f\"{epi_idx:06d}\",\n",
    "        \"length\": num_frames\n",
    "    })\n",
    "\n",
    "######################## META ########################\n",
    "\n",
    "# modality.json (y chang code g·ªëc)\n",
    "\n",
    "modality = {\n",
    "    \"video\": [\"observation.images.cam_head\"],\n",
    "    \"state\": list(metadata_ref.get(\"state_keys\", [])),\n",
    "    \"action\": list(metadata_ref.get(\"action_keys\", [])),\n",
    "    \"language\": list(metadata_ref.get(\"language_keys\", []))\n",
    "}\n",
    "\n",
    "with open(f\"{dst_folder}/meta/modality.json\",\"w\") as f:\n",
    "    json.dump(modality,f,indent=2)\n",
    "\n",
    "# info.json\n",
    "\n",
    "info = {\n",
    "    \"embodiment_tag\":\"m2\",\n",
    "    \"num_episodes\": len(episodes),\n",
    "    \"other_info\": metadata_ref.get(\"other_info\",{})\n",
    "}\n",
    "\n",
    "with open(f\"{dst_folder}/meta/info.json\",\"w\") as f:\n",
    "    json.dump(info,f,indent=2)\n",
    "\n",
    "# episodes.jsonl\n",
    "\n",
    "with open(f\"{dst_folder}/meta/episodes.jsonl\",\"w\") as f:\n",
    "    for e in episodes_jsonl:\n",
    "        f.write(json.dumps(e)+\"\\n\")\n",
    "\n",
    "# tasks.jsonl\n",
    "\n",
    "if \"tasks\" in metadata_ref:\n",
    "    with open(f\"{dst_folder}/meta/tasks.jsonl\",\"w\") as f:\n",
    "        for t in metadata_ref[\"tasks\"]:\n",
    "            f.write(json.dumps(t)+\"\\n\")\n",
    "\n",
    "# stats.json (GLOBAL gi·ªëng single version)\n",
    "\n",
    "state_array = np.array(all_states)\n",
    "action_array = np.array(all_actions)\n",
    "\n",
    "stats = {\n",
    "    \"state\":{\n",
    "        \"mean\": state_array.mean(0).tolist(),\n",
    "        \"std\": state_array.std(0).tolist(),\n",
    "        \"min\": state_array.min(0).tolist(),\n",
    "        \"max\": state_array.max(0).tolist()\n",
    "    },\n",
    "    \"action\":{\n",
    "        \"mean\": action_array.mean(0).tolist(),\n",
    "        \"std\": action_array.std(0).tolist(),\n",
    "        \"min\": action_array.min(0).tolist(),\n",
    "        \"max\": action_array.max(0).tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{dst_folder}/meta/stats.json\",\"w\") as f:\n",
    "    json.dump(stats,f,indent=2)\n",
    "\n",
    "print(\"‚úÖ Converted multi-episode dataset to LeRobot format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321b4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuong310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
