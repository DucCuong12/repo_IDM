# IDM_dump Pipeline - Chi Tiáº¿t Input/Output

## ğŸ“‹ Tá»•ng Quan Folder Structure

```
IDM_dump/
â”œâ”€â”€ base.yaml                          # Config cÆ¡ báº£n cho IDM model
â”œâ”€â”€ split_video_instruction.py         # Script 1: TÃ¡ch video + extract instruction
â”œâ”€â”€ preprocess_video.py                # Script 2: Xá»­ lÃ½ video (crop/resize)
â”œâ”€â”€ raw_to_lerobot.py                  # Script 3: Convert to LeRobot format
â”œâ”€â”€ dump_idm_actions.py                # Script 4: Generate actions vá»›i IDM model
â”œâ”€â”€ global_metadata/                   # Metadata cho tá»«ng embodiment
â”‚   â”œâ”€â”€ franka/
â”‚   â”œâ”€â”€ g1/
â”‚   â”œâ”€â”€ gr1/
â”‚   â”œâ”€â”€ robocasa/
â”‚   â””â”€â”€ so100/
â”‚       â”œâ”€â”€ modality.json              # Loáº¡i dá»¯ liá»‡u cÃ³ trong dataset
â”‚       â””â”€â”€ stats.json                 # Thá»‘ng kÃª normalize values
â””â”€â”€ scripts/preprocess/
    â”œâ”€â”€ m2.sh                          # Pipeline cho M2 embodiment
    â”œâ”€â”€ franka.sh
    â”œâ”€â”€ gr1.sh
    â”œâ”€â”€ robocasa.sh
    â”œâ”€â”€ g1.sh
    â””â”€â”€ so100.sh
```

---

## ğŸ”„ Pipeline Chi Tiáº¿t (M2 Example)

### **Step 1: split_video_instruction.py**
**Input:**
```
/mnt/ssd/project/data-pipeline/GR00T-Dreams/data/pick_bottle/videos/chunk-000/observation.images.cam_head/
â”œâ”€â”€ 1_pick_up_object.mp4
â”œâ”€â”€ 2_place_down_carefully.mp4
â””â”€â”€ 3_rotate_left_side.mp4
```

**Output:**
```
IDM_dump/data/m2/
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ 1.txt (ná»™i dung: "pick up object")
â”‚   â”œâ”€â”€ 2.txt (ná»™i dung: "place down carefully")
â”‚   â””â”€â”€ 3.txt (ná»™i dung: "rotate left side")
â””â”€â”€ videos/
    â”œâ”€â”€ 1.mp4 (copy cá»§a 1_pick_up_object.mp4)
    â”œâ”€â”€ 2.mp4
    â””â”€â”€ 3.mp4
```

**Xá»­ lÃ½:**
- TrÃ­ch xuáº¥t instruction tá»« filename
- Rename video thÃ nh sá»‘ thá»© tá»±
- TÃ¡ch instruction vÃ o file .txt riÃªng

---

### **Step 2: preprocess_video.py**
**Input:**
```
IDM_dump/data/m2/
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ 1.txt
â”‚   â”œâ”€â”€ 2.txt
â”‚   â””â”€â”€ 3.txt
â””â”€â”€ videos/
    â”œâ”€â”€ 1.mp4 (832x480, chá»©a 3 camera views)
    â”œâ”€â”€ 2.mp4
    â””â”€â”€ 3.mp4
```

**Output:**
```
IDM_dump/data/m2_split/
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ 1.txt (copy)
â”‚   â”œâ”€â”€ 2.txt
â”‚   â””â”€â”€ 3.txt
â””â”€â”€ videos/
    â””â”€â”€ observation.images.cam_head/
        â”œâ”€â”€ 1.mp4 (256x256, Ä‘Ã£ xá»­ lÃ½/normalize)
        â”œâ”€â”€ 2.mp4
        â””â”€â”€ 3.mp4
```

**Xá»­ lÃ½:**
- Chia frame 832x480 thÃ nh 3 camera views
- Resize & pad má»—i view â†’ 256x256
- TrÃ­ch xuáº¥t subimages theo dataset type (m2, franka, robocasa, etc.)

---

### **Step 3: raw_to_lerobot.py**
**Input:**
```
IDM_dump/data/m2_split/
â”œâ”€â”€ labels/
â”‚   â””â”€â”€ 1.txt
â””â”€â”€ videos/
    â””â”€â”€ observation.images.cam_head/
        â””â”€â”€ 1.mp4
```

**Output:**
```
IDM_dump/data/m2_unified.data/
â”œâ”€â”€ meta/
â”‚   â”œâ”€â”€ info.json          # Metadata tá»•ng há»£p (tá»•ng episodes, frames, tasks, fps)
â”‚   â”œâ”€â”€ tasks.jsonl        # Danh sÃ¡ch task (instruction)
â”‚   â”œâ”€â”€ episodes.jsonl     # Chi tiáº¿t tá»«ng episode
â”‚   â”œâ”€â”€ modality.json      # Copy tá»« global_metadata/m2/modality.json
â”‚   â””â”€â”€ stats.json         # Copy tá»« global_metadata/m2/stats.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chunk-000/
â”‚       â”œâ”€â”€ episode_000000.parquet  # Frame data (state, action, timestamp, task_index)
â”‚       â”œâ”€â”€ episode_000001.parquet
â”‚       â””â”€â”€ ...
â””â”€â”€ videos/
    â””â”€â”€ chunk-000/
        â””â”€â”€ observation.images.cam_head/
            â”œâ”€â”€ episode_000000.mp4
            â”œâ”€â”€ episode_000001.mp4
            â””â”€â”€ ...
```

**Xá»­ lÃ½:**
- Convert video frame/annotation thÃ nh LeRobot format
- Táº¡o Parquet files vá»›i:
  - `observation.state`: Robot state (44 dims)
  - `action`: Robot action (44 dims)
  - `timestamp`: Thá»i gian frame
  - `task_index`: Index cá»§a instruction
- Táº¡o metadata files (tasks.jsonl, episodes.jsonl, info.json)
- Copy video vÃ o cáº¥u trÃºc LeRobot
- Copy modality.json & stats.json tá»« global_metadata

**Tham sá»‘ quan trá»ng:**
- `--fps 16`: Frame rate (16 fps cho cosmos_predict2)
- `--cosmos_predict2`: Mode cá»‘ Ä‘á»‹nh 93 frames/video
- `--embodiment m2`: XÃ¡c Ä‘á»‹nh embodiment (robot type)

---

### **Step 4: dump_idm_actions.py**
**Input:**
```
1. IDM_dump/data/m2_unified.data/    # Dataset á»Ÿ format LeRobot
2. /mnt/ssd/project/GR00T-Dreams/idm/m2/checkpoint-10000  # Pre-trained IDM model
```

**Output:**
```
IDM_dump/data/m2_unified.data/
â””â”€â”€ meta/
    â””â”€â”€ actions.jsonl  # Generated actions tá»« IDM model
```

**Xá»­ lÃ½:**
- Load pre-trained IDM (Inverse Dynamics Model) checkpoint
- Load dataset tá»« LeRobot format
- Inference: Video frame â†’ Predicted actions
- Save actions vÃ o actions.jsonl

**Tham sá»‘:**
- `--checkpoint`: Path Ä‘áº¿n model checkpoint
- `--dataset`: Path Ä‘áº¿n LeRobot dataset
- `--video_indices "0 8"`: Video delta indices Ä‘á»ƒ model sá»­ dá»¥ng
- `--num_gpus 8`: Sá»‘ GPU Ä‘á»ƒ inference
- `--output_dir`: Output (ghi vÃ o cÃ¹ng dataset)

---

## ğŸ“¦ Requirements

### **Python Dependencies:**
```
opencv-python (cv2)
numpy
pandas
torch
tqdm
decord                 # Video reading
imageio               # Video writing
omegaconf / hydra     # Config management
tianshou              # Batch processing
huggingface_hub       # Download models
```

### **System Requirements:**
- **Video codec support**: ffmpeg, ffprobe (Ä‘á»ƒ láº¥y metadata video)
- **GPU**: Khuyáº¿n khÃ­ch cho step 4 (dump_idm_actions)
- **Storage**: 
  - Input video (m2) â‰ˆ 100GB
  - Preprocessed (m2_split) â‰ˆ 50GB  
  - LeRobot format (m2_unified.data) â‰ˆ 100GB (include video + parquet files)

### **Model Checkpoints:**
- `/mnt/ssd/project/GR00T-Dreams/idm/m2/checkpoint-10000` (cho M2)
- TÆ°Æ¡ng tá»± cho cÃ¡c embodiment khÃ¡c (franka, gr1, robocasa, etc.)

### **Metadata Files:**
- `IDM_dump/global_metadata/{embodiment}/modality.json`
- `IDM_dump/global_metadata/{embodiment}/stats.json`

---

## ğŸ¯ Input/Output Summary

| Script | Input | Output | Dependencies |
|--------|-------|--------|--------------|
| **split_video_instruction.py** | Raw video files (MP4) | Organized videos + labels | ffprobe |
| **preprocess_video.py** | Organized videos | Preprocessed videos (256x256) | opencv, decord, imageio |
| **raw_to_lerobot.py** | Preprocessed videos | LeRobot format dataset | pandas, subprocess (ffprobe) |
| **dump_idm_actions.py** | LeRobot dataset + IDM checkpoint | actions.jsonl | torch, hydra, tianshou, huggingface_hub |

---

## ğŸš€ CÃ¡ch Cháº¡y

```bash
# Cháº¡y toÃ n bá»™ pipeline cho M2
bash IDM_dump/scripts/preprocess/m2.sh

# Hoáº·c cháº¡y tá»«ng step riÃªng
python IDM_dump/split_video_instruction.py \
    --source_dir "..." \
    --output_dir "IDM_dump/data/m2"

python IDM_dump/preprocess_video.py \
    --src_dir "IDM_dump/data/m2" \
    --dst_dir "IDM_dump/data/m2_split" \
    --dataset m2

python IDM_dump/raw_to_lerobot.py \
    --input_dir "IDM_dump/data/m2_split" \
    --output_dir "IDM_dump/data/m2_unified.data" \
    --embodiment m2 \
    --cosmos_predict2

python IDM_dump/dump_idm_actions.py \
    --checkpoint "path/to/checkpoint-10000" \
    --dataset "IDM_dump/data/m2_unified.data" \
    --output_dir "IDM_dump/data/m2_unified.data" \
    --num_gpus 8 \
    --video_indices "0 8"
```

---

## ğŸ“Š Data Flow Visualization

```
Raw Videos (832x480)
    â†“
[split_video_instruction.py]
    â†“
Labeled Videos + Instructions
    â†“
[preprocess_video.py]
    â†“
Preprocessed Videos (256x256, 3 views)
    â†“
[raw_to_lerobot.py]
    â†“
LeRobot Format Dataset
â”œâ”€â”€ Parquet files (state, action, timestamp)
â”œâ”€â”€ Video files (reorganized)
â”œâ”€â”€ Metadata (tasks, episodes, info)
â””â”€â”€ Stats (modality, normalization)
    â†“
[dump_idm_actions.py] (Optional - IDM inference)
    â†“
Final Dataset with Predicted Actions
```

---

## âœ… Checklist TrÆ°á»›c Khi Cháº¡y

- [ ] CÃ³ raw video files táº¡i Ä‘Ãºng path
- [ ] ffmpeg & ffprobe Ä‘Æ°á»£c cÃ i
- [ ] Python dependencies Ä‘Ã£ install
- [ ] CÃ³ Ä‘á»§ disk space (~250GB cho M2)
- [ ] IDM checkpoint tá»“n táº¡i (cho step 4)
- [ ] global_metadata files tá»“n táº¡i
- [ ] GPU available (cho step 4)

